{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fala dev! \n",
    "Nesse notebook nós vamos começar a entender como inicializar um projeto, como funciona um ambiente virtual e como instalar as bibliotecas necessárias para o nosso projeto. \n",
    "\n",
    "Iremos entender também como usar os tokens e já indicar para você o caminho para a proximas etapas. Então, vamos lá!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de começar a qualquer projeto, é interessante você criar um ambiente virtual. \n",
    "### Mas o que é um ambiente virtual?\n",
    "Ambiente virtual é um ambiente isolado do seu sistema operacional, onde você pode instalar as bibliotecas necessárias para o seu projeto sem interferir no seu sistema operacional.\n",
    "\n",
    "Olhe o exemplo abaixo de como instalar um ambiente virtual no seu sistema operacional:\n",
    "\n",
    "```bash\n",
    "pip install virtualenv\n",
    "```\n",
    "\n",
    "Feito isso, você pode criar um ambiente virtual com o comando abaixo:\n",
    "\n",
    "```bash\n",
    "virtualenv nome_do_seu_ambiente\n",
    "```\n",
    "Em geral chamamos o ambiente virtual de `env`, ou `venv`, mas você pode chamar do que quiser.\n",
    "\n",
    "Para ativar o ambiente virtual, você pode usar o comando abaixo:\n",
    "\n",
    "```bash\n",
    "cd nome_do_seu_ambiente/Scrips\n",
    ".\\activate\n",
    "```\n",
    "\n",
    "Se você observar o seu terminal, você verá que o nome do seu ambiente virtual aparecerá antes do seu nome de usuário.\n",
    "(Ex: (nome_do_seu_ambiente) C:\\Users\\seu_nome_de_usuario>)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem agora que voçê já sabe o que é um ambiente virtual, vamos instalar as bibliotecas necessárias para o nosso projeto.\n",
    "\n",
    "Para isso muitas vezes usamos o arquivo `requirements.txt` que contém todas as bibliotecas necessárias para o nosso projeto.\n",
    "\n",
    "Obs: É importante que na construão do projeto a medida que você for instalando as bibliotecas, você vá atualizando o arquivo `requirements.txt`.\n",
    "\n",
    "Para instalar as bibliotecas necessárias para o nosso projeto, você pode usar o comando abaixo:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens\n",
    "\n",
    "Para você conseguir acessar a API da OpenAI, você precisa de um token. Para conseguir um token, você precisa se cadastrar no site da OpenAI e solicitar um token, mas provavelmente o grade mestre senhor kaiô ja lhe passou seu token no privado.\n",
    "\n",
    "### Próximos passos\n",
    "Crie um arquivo `.env` e coloque o seu token lá. \n",
    "\n",
    "```bash\n",
    "OPENAI_API_KEY=seu_token\n",
    "```\n",
    "\n",
    "Agora que você já tem o seu ambiente virtual, já instalou as bibliotecas necessárias e já tem o seu token, você já está pronto para começar a codar... ou não."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agora vamos ver como o modelo fuciona via API\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deu errado? Não esqueceu de dar pip install nessa nova biblioteca que você quer utilizar?\n",
    "\n",
    "Já atualizou o requirements.txt hoje irmão?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender mais sobre ChatOpenAI, você pode acessar a documentação da OpenAI [aqui](https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='A capital do Brasil é Brasília.' response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 14, 'total_tokens': 22}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-1c3cf1c5-3cde-4e1a-89ea-9d9a17975e58-0' usage_metadata={'input_tokens': 14, 'output_tokens': 8, 'total_tokens': 22}\n"
     ]
    }
   ],
   "source": [
    "# Vamos fazer uma pergunta\n",
    "question = \"Qual é a capital do Brasil?\"\n",
    "answer = llm.invoke(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos orientar resposta do modelo com um modelo de prompt \n",
    "# Esse modelo de prompt é uma string que é usada para orientar a resposta do modelo\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Voçê é um ajudante de aluno e está respondendo perguntas de geografia.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cadeia de comandos\n",
    "Chains of commands, ou cadeia de comandos, é uma sequência de comandos que são executados em sequência.\n",
    "\n",
    "Vamos combinar os comandos anteriores no que chamamos de chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos invocá-lo e fazer a mesma pergunta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A capital do Brasil é Brasília.', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 37, 'total_tokens': 45}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-217cd654-27f4-4dc1-af8f-523908b5c3c1-0', usage_metadata={'input_tokens': 37, 'output_tokens': 8, 'total_tokens': 45})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"Qual é a capital do Brasil?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A saída de um ChatModel (e, portanto, desta cadeia) é uma mensagem. No entanto, muitas vezes é muito mais conveniente trabalhar com strings. \n",
    "\n",
    "Vamos adicionar um analisador de saída simples para converter a mensagem de chat em uma string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A capital do Brasil é Brasília.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"Qual é a capital do Brasil?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem, essa é uma aplicação simples de cadeia de comandos. É possível criar cadeias de comandos mais complexas, \n",
    "\n",
    "com várias entradas e saídas, e até mesmo cadeias de comandos que chamam outras cadeias de comandos.\n",
    "\n",
    "Se aventure e crie suas chains pequeno garfanhoto.\n",
    "\n",
    "mais informações sobre chains [aqui](https://python.langchain.com/v0.1/docs/expression_language/cookbook/multiple_chains/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
